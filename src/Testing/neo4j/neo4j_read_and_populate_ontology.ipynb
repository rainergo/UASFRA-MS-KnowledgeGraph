{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Ontology Driven KG creation",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyPa90V5qw4Hy/CLydkkxIwD",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import rdflib\n",
    "import time\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from settings import path_base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_to_secrets = pathlib.Path(path_base, 'secrets.env')\n",
    "try:\n",
    "    load_dotenv(dotenv_path=path_to_secrets)  # Load secrets/env variables\n",
    "except:\n",
    "    print('secrets could not be loaded!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#utility function to get the local part of a URI (stripping out the namespace)\n",
    "\n",
    "def getLocalPart(uri):\n",
    "  pos = -1\n",
    "  pos = uri.rfind('#') \n",
    "  if pos < 0 :\n",
    "    pos = uri.rfind('/')  \n",
    "  if pos < 0 :\n",
    "    pos = uri.rindex(':')\n",
    "  return uri[pos+1:]\n",
    "\n",
    "def getNamespacePart(uri):\n",
    "  pos = -1\n",
    "  pos = uri.rfind('#') \n",
    "  if pos < 0 :\n",
    "    pos = uri.rfind('/')  \n",
    "  if pos < 0 :\n",
    "    pos = uri.rindex(':')\n",
    "  return uri[0:pos+1]\n",
    "\n",
    "# quick test\n",
    "print(getLocalPart(\"http://onto.neo4j.com/rail#Station\"))\n",
    "print(getNamespacePart(\"http://onto.neo4j.com/rail#Station\"))"
   ],
   "metadata": {
    "id": "eRYK8Uvk67jQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Own ontology:\n",
    "# path_to_ontology = pathlib.Path(path_base, \"models/Ontologies/Ontology_Simple.ttl\")\n",
    "# From tutorial:\n",
    "path_to_ontology = \"https://raw.githubusercontent.com/jbarrasa/goingmeta/main/session5/ontos/rail.ttl\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = rdflib.Graph()\n",
    "g.parse(source=path_to_ontology, format='turtle')\n",
    "\n",
    "simple_query = \"\"\"\n",
    "prefix owl: <http://www.w3.org/2002/07/owl#>\n",
    "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "\n",
    "SELECT DISTINCT ?c\n",
    "  WHERE {\n",
    "    ?c rdf:type owl:Class .    \n",
    "  } \"\"\"\n",
    "\n",
    "for row in g.query(simple_query):\n",
    "    print('URI: ', str(row.c),'\\nCLASS: ',getLocalPart(str(row.c)),'\\nNAMESPACE: ',getNamespacePart(str(row.c)))\n",
    "    # print(str(row.c))\n",
    "    # print(str(getLocalPart(str(row.c))))\n",
    "    print('-----------------------------------------------------------')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read the onto and generate cypher (complete without mappings)\n",
    "\n",
    "g = rdflib.Graph()\n",
    "g.parse(\"https://raw.githubusercontent.com/jbarrasa/goingmeta/main/session5/ontos/rail.ttl\", format='turtle')\n",
    "\n",
    "classes_and_props_query = \"\"\"\n",
    "prefix owl: <http://www.w3.org/2002/07/owl#> \n",
    "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "\n",
    "SELECT DISTINCT ?curi (GROUP_CONCAT(DISTINCT ?propTypePair ; SEPARATOR=\",\") AS ?props)\n",
    "WHERE {\n",
    "    ?curi rdf:type owl:Class .\n",
    "    optional { \n",
    "      ?prop rdfs:domain ?curi ;\n",
    "        a owl:DatatypeProperty ;\n",
    "        rdfs:range ?range .\n",
    "      BIND (concat(str(?prop),';',str(?range)) AS ?propTypePair)\n",
    "    }\n",
    "  } GROUP BY ?curi  \"\"\"\n",
    "\n",
    "query_result_classes_and_props = g.query(classes_and_props_query)\n",
    "print(query_result_classes_and_props.vars)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cypher_list = []\n",
    "\n",
    "for row in query_result_classes_and_props:\n",
    "    cypher = []\n",
    "    cypher.append(\"unwind $records AS record\")\n",
    "    cypher.append(\"merge (n:\" + getLocalPart(row.curi) + \" { `<id_prop>`: record.`<col with id>`} )\")\n",
    "    print('getLocalPart(row.curi):', getLocalPart(row.curi))\n",
    "    for pair in row.props.split(\",\"):\n",
    "        propName = pair.split(\";\")[0]\n",
    "        print('propName:', propName)\n",
    "        propType = pair.split(\";\")[1]\n",
    "        print('propType:', propType)\n",
    "        cypher.append(\"set n.\" + getLocalPart(propName) + \" = record.`<col with value for \" + getLocalPart(propName) + \">`\")\n",
    "        print('getLocalPart(propName):', getLocalPart(propName))    \n",
    "        print('     ----- inner ------')\n",
    "    print('----- OUTER -----')\n",
    "    cypher.append(\"return count(*) as total\") \n",
    "    cypher_list.append(' \\n'.join(cypher))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rels_query = \"\"\"\n",
    "prefix owl: <http://www.w3.org/2002/07/owl#> \n",
    "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "\n",
    "SELECT DISTINCT ?rel ?dom ?ran #(GROUP_CONCAT(DISTINCT ?relTriplet ; SEPARATOR=\",\") AS ?rels)\n",
    "WHERE {\n",
    "    ?rel a ?propertyClass .\n",
    "    filter(?propertyClass in (rdf:Property, owl:ObjectProperty, owl:FunctionalProperty, owl:AsymmetricProperty, \n",
    "           owl:InverseFunctionalProperty, owl:IrreflexiveProperty, owl:ReflexiveProperty, owl:SymmetricProperty, owl:TransitiveProperty))\n",
    "    \n",
    "    ?rel rdfs:domain ?dom ;\n",
    "      rdfs:range ?ran .\n",
    "    \n",
    "    #BIND (concat(str(?rel),';',str(?dom),';',str(?range)) AS ?relTriplet)\n",
    "    \n",
    "  }\"\"\"\n",
    "\n",
    "query_result_relations = g.query(rels_query)\n",
    "print(query_result_relations.vars)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for row in query_result_relations:\n",
    "    cypher = []\n",
    "    cypher.append(\"unwind $records AS record\")\n",
    "    cypher.append(\"match (source:\" + getLocalPart(row.dom) + \" { `<id_prop>`: record.`<col with source id>`} )\")\n",
    "    cypher.append(\"match (target:\" + getLocalPart(row.ran) + \" { `<id_prop>`: record.`<col with target id>`} )\")\n",
    "    cypher.append(\"merge (source)-[r:`\"+ getLocalPart(row.rel) +\"`]->(target)\")\n",
    "    cypher.append(\"return count(*) as total\") \n",
    "    for item in cypher:\n",
    "        print('cypher-item:\\n', item)\n",
    "    print('---------------------------------------')\n",
    "    cypher_list.append(' \\n'.join(cypher))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for q in cypher_list:\n",
    "    print(\"\\n\\n\" + q)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "railMappings = {}\n",
    "\n",
    "stationMapping = {}\n",
    "stationMapping[\"@fileName\"] = \"https://raw.githubusercontent.com/jbarrasa/goingmeta/main/session5/data/nr-stations-all.csv\"\n",
    "stationMapping[\"@uniqueId\"] = \"stationCode\"\n",
    "stationMapping[\"lat\"] = \"lat\"\n",
    "stationMapping[\"long\"] = \"long\"\n",
    "stationMapping[\"stationAddress\"] = \"address\"\n",
    "stationMapping[\"stationCode\"] = \"crs\"\n",
    "stationMapping[\"stationName\"] = \"name\"\n",
    "railMappings[\"Station\"] = stationMapping\n",
    "\n",
    "eventMapping = {}\n",
    "eventMapping[\"@fileName\"] = \"https://raw.githubusercontent.com/jbarrasa/goingmeta/main/session5/data/nr-events.csv\"\n",
    "eventMapping[\"@uniqueId\"] = \"eventId\"\n",
    "eventMapping[\"eventDescription\"] = \"desc\"\n",
    "eventMapping[\"eventId\"] = \"id\"\n",
    "eventMapping[\"timestamp\"] = \"ts\"\n",
    "eventMapping[\"eventType\"] = \"type\"\n",
    "railMappings[\"Event\"] = eventMapping\n",
    "\n",
    "linkMapping = {}\n",
    "linkMapping[\"@fileName\"] = \"https://raw.githubusercontent.com/jbarrasa/goingmeta/main/session5/data/nr-station-links.csv\"\n",
    "linkMapping[\"@from\"] = \"origin\"\n",
    "linkMapping[\"@to\"] = \"destination\"\n",
    "railMappings[\"link\"] = linkMapping\n",
    "\n",
    "affectsMapping = {}\n",
    "affectsMapping[\"@fileName\"] = \"https://raw.githubusercontent.com/jbarrasa/goingmeta/main/session5/data/nr-events.csv\"\n",
    "affectsMapping[\"@from\"] = \"id\"\n",
    "affectsMapping[\"@to\"] = \"Station\"\n",
    "railMappings[\"affects\"] = affectsMapping\n",
    "\n",
    "# show it?\n",
    "railMappings"
   ],
   "metadata": {
    "id": "F4GP70jAf8v2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#copy of previous but using the mappings\n",
    "def getLoadersFromOnto(onto, rdf_format, mappings):\n",
    "    g = rdflib.Graph()\n",
    "    g.parse(onto, format=rdf_format)\n",
    "\n",
    "    classes_and_props_query = \"\"\"\n",
    "    prefix owl: <http://www.w3.org/2002/07/owl#> \n",
    "    prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "    \n",
    "    SELECT DISTINCT ?curi (GROUP_CONCAT(DISTINCT ?propTypePair ; SEPARATOR=\",\") AS ?props)\n",
    "    WHERE {\n",
    "      ?curi rdf:type owl:Class .\n",
    "      optional { \n",
    "        ?prop rdfs:domain ?curi ;\n",
    "          a owl:DatatypeProperty ;\n",
    "          rdfs:range ?range .\n",
    "        BIND (concat(str(?prop),';',str(?range)) AS ?propTypePair)\n",
    "      }\n",
    "    } GROUP BY ?curi  \"\"\"\n",
    "    \n",
    "    cypher_import = {}\n",
    "    export_ns = set()\n",
    "    export_mappings = {}\n",
    "    \n",
    "    for row in g.query(classes_and_props_query):\n",
    "        export_ns.add(getNamespacePart(row.curi))\n",
    "        export_mappings[getLocalPart(row.curi)] = str(row.curi)\n",
    "        cypher = []\n",
    "        cypher.append(\"unwind $records AS record\")\n",
    "        cypher.append(\"merge (n:\" + getLocalPart(row.curi) + \" { `\" + mappings[getLocalPart(row.curi)][\"@uniqueId\"] + \"`: record.`\" + mappings[getLocalPart(row.curi)][mappings[getLocalPart(row.curi)][\"@uniqueId\"]] + \"`} )\")\n",
    "        for pair in row.props.split(\",\"):      \n",
    "            propName = pair.split(\";\")[0]\n",
    "            propType = pair.split(\";\")[1]\n",
    "            export_ns.add(getNamespacePart(propName))\n",
    "            export_mappings[getLocalPart(propName)] = propName\n",
    "            #if a mapping (a column in the source file) is defined for the property and property is not a unique id\n",
    "            if getLocalPart(propName) in mappings[getLocalPart(row.curi)] and getLocalPart(propName) != mappings[getLocalPart(row.curi)][\"@uniqueId\"]:\n",
    "                cypher.append(\"set n.\" + getLocalPart(propName) + \" = record.`\" + mappings[getLocalPart(row.curi)][getLocalPart(propName)] + \"`\")\n",
    "        cypher.append(\"return count(*) as total\") \n",
    "        cypher_import[getLocalPart(row.curi)] = ' \\n'.join(cypher)\n",
    "        print('CYPHER in classes_and_props_query:\\n', cypher)\n",
    "\n",
    "\n",
    "    rels_query = \"\"\"\n",
    "    prefix owl: <http://www.w3.org/2002/07/owl#> \n",
    "    prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "    \n",
    "    SELECT DISTINCT ?rel ?dom ?ran #(GROUP_CONCAT(DISTINCT ?relTriplet ; SEPARATOR=\",\") AS ?rels)\n",
    "    WHERE {\n",
    "      ?rel a ?propertyClass .\n",
    "      filter(?propertyClass in (rdf:Property, owl:ObjectProperty, owl:FunctionalProperty, owl:AsymmetricProperty, \n",
    "            owl:InverseFunctionalProperty, owl:IrreflexiveProperty, owl:ReflexiveProperty, owl:SymmetricProperty, owl:TransitiveProperty))\n",
    "      \n",
    "      ?rel rdfs:domain ?dom ;\n",
    "        rdfs:range ?ran .\n",
    "      \n",
    "      #BIND (concat(str(?rel),';',str(?dom),';',str(?range)) AS ?relTriplet)\n",
    "      \n",
    "    }\"\"\"\n",
    "\n",
    "    for row in g.query(rels_query):\n",
    "        export_ns.add(getNamespacePart(row.rel))\n",
    "        export_mappings[getLocalPart(row.rel)] = str(row.rel)\n",
    "        cypher = []\n",
    "        cypher.append(\"unwind $records AS record\")\n",
    "        cypher.append(\"match (source:\" + getLocalPart(row.dom) + \" { `\" + mappings[getLocalPart(row.dom)][\"@uniqueId\"] + \"`: record.`\" + mappings[getLocalPart(row.rel)][\"@from\"] + \"`} )\")\n",
    "        cypher.append(\"match (target:\" + getLocalPart(row.ran) + \" { `\" + mappings[getLocalPart(row.ran)][\"@uniqueId\"] + \"`: record.`\" + mappings[getLocalPart(row.rel)][\"@to\"] + \"`} )\")\n",
    "        cypher.append(\"merge (source)-[r:`\"+ getLocalPart(row.rel) +\"`]->(target)\")\n",
    "        cypher.append(\"return count(*) as total\") \n",
    "        cypher_import[getLocalPart(row.rel)] = ' \\n'.join(cypher)\n",
    "        print('CYPHER in rels_query:\\n', cypher)\n",
    "\n",
    "\n",
    "    nscount = 0\n",
    "    mapping_export_cypher = []\n",
    "    \n",
    "    for ns in export_ns:\n",
    "        mapping_export_cypher.append(\"call n10s.nsprefixes.add('ns\" + str(nscount) + \"','\" + ns + \"');\")\n",
    "        nscount+=1\n",
    "    \n",
    "    for k in export_mappings.keys():\n",
    "        mapping_export_cypher.append(\"call n10s.mapping.add('\" + export_mappings[k] + \"','\" + k + \"');\")\n",
    "    \n",
    "    return cypher_import ,  mapping_export_cypher\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cypher_import , mapping_defs = getLoadersFromOnto(\"https://raw.githubusercontent.com/jbarrasa/goingmeta/main/session5/ontos/rail.ttl\",\"turtle\",railMappings)\n",
    "\n",
    "print(\"#LOADERS:\\n\\n\")\n",
    "for q in cypher_import.keys():\n",
    "  print(q + \": \\n\\nfile: \" + railMappings[q][\"@fileName\"] + \"\\n\\n\"+ cypher_import[q] + \"\\n\\n\")\n",
    "\n",
    "print(\"#EXPORT MAPPINGS (for RDF API):\\n\\n\")\n",
    "for md in mapping_defs:\n",
    "  print(md)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Utility function to write to Neo4j in batch mode.\n",
    "\n",
    "def insert_data(session, query, frame, batch_size = 500):\n",
    "    \n",
    "    print('QUERY:\\n', query)\n",
    "    print('---------------------------')\n",
    "    \n",
    "    total = 0\n",
    "    batch = 0\n",
    "    start = time.time()\n",
    "    result = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    while batch * batch_size < len(frame):\n",
    "        res = session.write_transaction( lambda tx: tx.run(query,\n",
    "                      parameters = {'records': frame[batch*batch_size:(batch+1)*batch_size].to_dict('records')}).data())\n",
    "\n",
    "        total += res[0]['total']\n",
    "        batch += 1\n",
    "        result = {\"total\":total, \n",
    "                  \"batches\":batch, \n",
    "                  \"time\":time.time()-start}\n",
    "        print(result)\n",
    "        \n",
    "    return result\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase, basic_auth\n",
    "\n",
    "uri = \"neo4j://localhost:7687\"\n",
    "auth = (\"neo4j\", os.getenv('NEO4J_PW'))\n",
    "driver = GraphDatabase.driver(uri, auth=auth)\n",
    "\n",
    "session = driver.session(database=\"neo4j\")\n",
    "\n",
    "cypher_import , mapping_defs = getLoadersFromOnto(\"https://raw.githubusercontent.com/jbarrasa/goingmeta/main/session5/ontos/rail.ttl\",\"turtle\",railMappings)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(cypher_import)\n",
    "print('----------------------------------')\n",
    "pprint(mapping_defs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for q in cypher_import.keys():\n",
    "    print(\"about to import \" + q + \" from file \" + railMappings[q][\"@fileName\"])\n",
    "    df = pd.read_csv(railMappings[q][\"@fileName\"])\n",
    "    result = insert_data(session, cypher_import[q], df, batch_size = 300) \n",
    "    print(result)\n",
    "\n",
    "for md in mapping_defs:\n",
    "    session.run(md)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
